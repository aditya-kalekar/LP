{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Churn Prediction with Text\n", "\n", "Customer churn is a problem faced by a wide range of companies, from\n", "telecommunications to banking, where customers are typically lost to\n", "competitors. It's in a company's best interest to retain existing\n", "customer instead of acquiring new customers because it usually costs\n", "significantly more to attract new customers. When trying to retain\n", "customers, companies often focus their efforts on customers who are more\n", "likely to leave. User behaviour and customer support chat logs can\n", "contain valuable indicators on the likelihood of a customer ending the\n", "service. In this solution, we train and deploy a churn prediction model\n", "that uses state-of-the-art natural language processing model to find\n", "useful signals in text. In addition to textual inputs, this model uses\n", "traditional structured data inputs such as numerical and categorical\n", "fields.\n", "\n", "In this notebook, we'll train, deploy and use a churn prediction model\n", "that processed numerical, categorical and textual features to make its\n", "prediction.\n", "\n", "**Note**: When running this notebook on SageMaker Studio, you should make\n", "sure the 'SageMaker JumpStart PyTorch 1.0' image/kernel is used. When\n", "running this notebook on SageMaker Notebook Instance, you should make\n", "sure the 'sagemaker-soln' kernel is used."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We start by importing a variety of packages that will be used throughout\n", "the notebook. One of the most important packages is the Amazon SageMaker\n", "Python SDK (i.e. `import sagemaker`). We also import modules from our own\n", "custom (and editable) package that can be found at `../package`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "from pathlib import Path\n", "import sagemaker\n", "from sagemaker.pytorch import PyTorch\n", "from sagemaker.predictor import json_serializer, json_deserializer\n", "import sys\n", "\n", "sys.path.insert(0, '../package')\n", "from package import config, utils"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Up next, we define the current folder and create a SageMaker client (from\n", "`boto3`). We can use the SageMaker client to call SageMaker APIs\n", "directly, as an alternative to using the Amazon SageMaker SDK. We'll use\n", "it at the end of the notebook to delete certain resources that are\n", "created in this notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["current_folder = utils.get_current_folder(globals())\n", "sagemaker_client = boto3.client('sagemaker')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sagemaker_session = sagemaker.Session()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!aws s3 cp --recursive --quiet $config.SOURCE_S3_PATH/data ../data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!aws s3 cp --recursive --quiet ../data s3://$config.S3_BUCKET/$config.DATASETS_S3_PREFIX"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hyperparameters = {\n", "    \"n-estimators\": 100,\n", "    \"numerical-feature-names\": \"CustServ Calls,Account Length\",\n", "    \"categorical-feature-names\": \"plan,limit\",\n", "    \"textual-feature-names\": \"text\",\n", "    \"label-name\": \"y\"\n", "}\n", "\n", "current_folder = utils.get_current_folder(globals())\n", "estimator = PyTorch(\n", "    framework_version='1.5.1',\n", "    entry_point='entry_point.py',\n", "    source_dir=str(Path(current_folder, '../containers/model').resolve()),\n", "    hyperparameters=hyperparameters,\n", "    role=config.IAM_ROLE,\n", "    train_instance_count=1,\n", "    train_instance_type=config.TRAINING_INSTANCE_TYPE,\n", "    output_path='s3://' + str(Path(config.S3_BUCKET, config.OUTPUTS_S3_PREFIX)),\n", "    code_location='s3://' + str(Path(config.S3_BUCKET, config.OUTPUTS_S3_PREFIX)),\n", "    base_job_name=config.SOLUTION_PREFIX,\n", "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n", "    sagemaker_session=sagemaker_session,\n", "    train_volume_size=30\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["estimator.fit({\n", "    'train': 's3://' + str(Path(config.S3_BUCKET, config.DATASETS_S3_PREFIX, 'train')),\n", "    'test': 's3://' + str(Path(config.S3_BUCKET, config.DATASETS_S3_PREFIX, 'test'))\n", "})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll use the unique solution prefix to name the model and endpoint."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_name = \"{}-churn-prediction\".format(config.SOLUTION_PREFIX)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictor = estimator.deploy(\n", "    endpoint_name=model_name,\n", "    instance_type=config.HOSTING_INSTANCE_TYPE,\n", "    initial_instance_count=1\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When calling our new endpoint from the notebook, we use a Amazon\n", "SageMaker SDK\n", "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n", "A `Predictor` is used to send data to an endpoint (as part of a request),\n", "and interpret the response. Our `estimator.deploy` command returned a\n", "`Predictor` but, by default, it will send and receive numpy arrays. Our\n", "endpoint expects to receive (and also sends) JSON formatted objects, so\n", "we modify the `Predictor` to use JSON instead of the PyTorch endpoint\n", "default of numpy arrays. JSON is used here because it is a standard\n", "endpoint format and the endpoint response can contain nested data\n", "structures."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictor.content_type = 'application/json'\n", "predictor.accept = 'application/json'\n", "predictor.serializer = json_serializer\n", "predictor.deserializer = json_deserializer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With our model successfully deployed and our predictor configured, we can\n", "try out the churn prediction model out on example inputs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = {\n", "    \"CustServ Calls\": -20.0,\n", "    \"Account Length\": 133.12,\n", "    \"plan\": \"D\",\n", "    \"limit\": \"unlimited\",\n", "    'text': \"Well, I've been dealing with TelCom for three months now, and I feel like they're very helpful and responsive to my issues, but for a month now, I've only had one technical support call and that was very long and involved. My phone number was wrong on both contracts, and they gave me a chance to work with TelCom customer service and it was extremely helpful, so I've decided to stick with it. But I would like to have more help in terms of technical support, I haven't had the kind of help with my phone line and I don't have the type of tech support I want. So I would like to negotiate a phone contract, maybe an upgrade from a Sprint plan, or maybe from a Verizon plan.\\nTelCom Agent: Very good.\"\n", "}\n", "response = predictor.predict(data=data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have the responce and we can print out the probability of churn."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"{:.2%} probability of churn\".format(response['probability']))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Caution**: the probability returned by this model has not been\n", "calibrated. When the model gives a probability of churn of 20%,\n", "for example, this does not necessarily mean that 20% of customers with\n", "a probability of 20% resulted in churn. Calibration is a useful\n", "property in certain circumstances, but is not required in cases where\n", "discrimination between cases of churn and non-churn is sufficient.\n", "[CalibratedClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html)\n", "from\n", "[Scikit-learn](https://scikit-learn.org/stable/modules/calibration.html)\n", "can be used to calibrate a model."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Clean Up\n", "\n", "When you've finished with the relationship extraction endpoint (and associated\n", "endpoint-config), make sure that you delete it to avoid accidental\n", "charges."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictor.delete_endpoint()\n", "predictor.delete_model()"]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}, "kernelspec": {"display_name": "sagemaker-soln", "language": "python", "name": "sagemaker-soln"}}, "nbformat": 4, "nbformat_minor": 4}